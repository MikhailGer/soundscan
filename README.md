
# SoundScan

**SoundScan** — это Python-приложение для сканирования, анализа и обработки звуковых файлов с использованием графического интерфейса на базе PyQt5. Проект сочетает в себе работу с аппаратными устройствами (Arduino), управлением базой данных, аудиоанализом и возможностями машинного обучения на базе Keras.

> **Нейросети уже в деле:** В проект интегрирован модуль обучения и использования моделей искусственного интеллекта (Keras), позволяющий классифицировать дефекты на основе аудиоданных.

## Особенности

- **Графический интерфейс:** Реализован с использованием PyQt5 и UI-файлов, созданных в Qt Designer.
- **Интеграция с Arduino:** Модули для работы с Arduino, включая сбор и передачу аудиосигналов.
- **Управление базой данных:** SQLAlchemy и Alembic используются для работы с БД и миграциями.
- **Аудиоанализ:** Воспроизведение и базовая обработка звука.
- **Обучение моделей Keras:** Пользователь может обучить нейросеть на размеченных данных и применять её для анализа новых измерений.
- **Сохранение моделей в базу:** Тренированные модели сохраняются в PostgreSQL (в base64-формате) и могут быть повторно загружены.
- **Автоматическое предсказание дефектов:** Модель на базе `Dense`-слоёв (MLP) предсказывает состояние лопаток ("Годен"/"Не годен") по признакам, извлечённым из WAV-файлов.

## Установка

1. **Клонируйте репозиторий:**
   ```bash
   git clone https://github.com/MikhailGer/soundscan.git
   cd soundscan
   ```

2. **Создайте виртуальное окружение (опционально):**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # для Linux/macOS
   .venv\Scripts\activate     # для Windows
   ```

3. **Установите зависимости:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Настройте переменные окружения и конфигурации при необходимости.**

## Использование

Запуск основного GUI:
```bash
python main.py
```
5. **Установите скрипт на вашу плату Arduino из папки scetch_soundscan и соберите установку(схема будет позже).**

Дополнительные скрипты:
- `arduino_service.py` — управление Arduino.
- `play_audio.py` — воспроизведение аудиофайлов.

## Структура проекта

```
├── main.py                        # Точка входа в приложение
├── requirements.txt              # Зависимости проекта
├── README.md
├── arduino_service.py           # Управление Arduino
├── play_audio.py                # Воспроизведение звука
├── sketch_soundscan/            # Arduino-скетчи
├── alembic/                     # Миграции базы данных
│   └── versions/                # История миграций
├── src/
│   ├── arduino/                 # Работа с Arduino
│   ├── interfaces/              # Автогенерированные UI-обёртки
│   ├── scan/
│   │   ├── Scanning.py          # Поддержка сканирования
│   │   └── ml_predict.py        # ML: обучение и предсказания
│   ├── windows/                 # Вкладки GUI
│   │   ├── ModelTrainingTab.py  # Обучение и сохранение модели
│   │   └── ...                  # Остальные вкладки
│   ├── db.py                    # Подключение к БД
│   ├── config.py                # Конфигурация
│   └── models.py                # SQLAlchemy модели
└── ui files/                    # Qt Designer UI-файлы
```

## Как работает машинное обучение

Модуль ML реализован на базе **Keras** (Sequential API). Алгоритм:
1. Пользователь размечает аудиоданные как "Годен"/"Не годен".
2. Из WAV-файлов извлекаются численные признаки.
3. Обучается модель (`Dense`-слои с `sigmoid`-выходом).
4. Модель сохраняется в базу данных.
5. Можно выполнить предсказание по одной лопатке — и получить результат с уверенностью.

Модель используется как бинарный классификатор:
- `0` → "Не годен"
- `1` → "Годен"
- Используется стандартный порог 0.5

## План развития

- Добавление CNN-моделей для работы с необработанным звуком (в будущем).
- Упрощение взаимодействия с Arduino.
- Расширение GUI и визуализация процесса обучения/предсказания.
- Автоматический подбор гиперпараметров.

## Вклад в проект

Буду рад pull request'ам, баг-репортам и предложениям. Если вам интересна тема анализа звука, интерфейсы или AI — добро пожаловать!

## Лицензия

Проект распространяется под лицензией MIT. Подробнее — в [LICENSE](LICENSE).
